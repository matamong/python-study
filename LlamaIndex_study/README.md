# 라이브러리 위치
- https://github.com/run-llama/llama_index


# 용어 정리 (헷갈리지 않게!)
- **벡터의 크기/길이(norm)**:  
  - 원점 (0,0,...)에서 **벡터 하나**까지의 거리  
  - `||v||` 로 표기
- **(벡터 사이) 거리(distance)**:
  - 벡터 A와 벡터 B, **두 점 사이의 거리**  
  - `||A - B||` 로 표기
- **축**
  - 실제 임베딩 공간에서는 각 축이 이런 식의 추상적인 feature 방향이라고 볼 수 있다:
  - 어떤 축은 “긍정 감성”
  - 어떤 축은 “기술/논문 스타일”
  - 어떤 축은 “캐주얼함/구어체 느낌”
  - 어떤 축은 “추천/선호도” …
  - ...
- **축과 길이**
  - 한 문장의 임베딩 벡터를 보면:
    - 각 좌표값 = 해당 feature 축 방향으로 얼마나 갔는지 (얼마나 켜졌는지)
    - 벡터의 크기(길이, norm) = 이 값들을 한꺼번에 모아서 본 전체적인 “세기” 정도로 볼 수 있다.
    - 좌표들이 전반적으로 크면
      - 여러 feature가 강하게 나타난 문장일 수 있고
    - 좌표들이 전반적으로 작으면
      -  전체적으로 약한/평이한 문장일 수 있다.
   - **단, 이 해석은 모델마다 다르고, 길이가 “확신도”를 반영하기도 하고 아무 의미 없는 스케일일 수도 있다. 그래서 실무에서는 아예 크기를 1로 맞춰버리고(정규화) 각도만 보는 경우도 많다.**

# L1, L2 정규화 개념 정리

## 1. 기본 세팅: 2D 평면 + 벡터 하나

벡터 하나 잡자:

* (x = (3, 4))

```text
      y ↑
    5 |        *
    4 |      x (3,4)
    3 |
    2 |
    1 |
    0 +----------------→ x
      0  1  2  3  4  5
```

이 (3,4) 점까지의 **화살표**가 벡터라고 생각하면 됨.

이때:

* **L2 길이(크기)** = 피타고라스 길이
  → √(3² + 4²) = 5
* **L1 길이(합)** = 절댓값 합
  → |3| + |4| = 7

---

## 2. L2 정규화: “원 위로 끌어내리기”

**L2 정규화=“길이를 1로 맞추기”**임.
(방향은 그대로, 길이만 1 되게 줄이기)

### 2-1. 2D에서 L2 = 원(circle)

“길이가 1인 벡터들”의 집합은 **원**이다:

```text
      y ↑

    1 |      * (0,1)
      |   .     .
      | .         .
    0 +*-----------*→ x
     -1  .       .  1
        .   . .   .
          * (0,-1)

(대충 반지름 1짜리 원)
```

* (1,0), (0,1), (-1,0), (0,-1) 같은 점들이 **L2 길이 = 1**

### 2-2. 우리 벡터 (3,4)를 원 위로!

원래 벡터:

* (3,4), L2 길이 = 5

L2 정규화:

* (3/5, 4/5) = (0.6, 0.8)
* 이 점은 “길이 1짜리 원” 위에 있게 됨.

ASCII 감으로 그리면:

```text
      y ↑
    1 |          * (0,1)
  0.8|        x̂ (0.6,0.8)
  0.6|
    0 +--------------------→ x
       0    0.6     1
```

느낌:

* 원래 (3,4)는 더 멀리 있었는데
* **같은 방향**으로 **슉 줄여서** 원 위로 올려놓는 거 = L2 정규화

> 👉 **L2 정규화 요약**
> “벡터를 자기 L2 길이로 나눠서,
> **길이 1짜리 화살표**로 만드는 것”

---

## 3. L1 정규화: “마름모(다이아) 위로 끌어내리기”

이번엔 **L1 정규화**.

### 3-1. 2D에서 L1 = 마름모(다이아몬드)

“|x| + |y| = 1”인 점들의 집합이 바로 **L1 노름 = 1** 인 점들임.

그려보면 이런 모양:

```text
      y ↑
        |
    1   * (0,1)
        |
        |
        |
-1 -----*----- 1 → x
        |
        |
        |
    -1  * (0,-1)
```

조금 더 디테일하게 보면:

```text
      y ↑
        |
    1   * (0,1)
        |\ 
        | \
        |  \
        |   \
-1 -----*----*---- 1 → x
        |   /
        |  /
        | /
    -1  * (0,-1)

   (|x| + |y| = 1 이 이루는 마름모)
```

코너 네 개:

* (1,0), (0,1), (-1,0), (0,-1)

이 점들은 L1 길이:

* |1|+|0| = 1
* |0|+|1| = 1  … 라서 **L1 = 1**

### 3-2. (3,4)를 L1 정규화하면?

원래: x = (3,4), L1 길이 = 7
L1 정규화:

* (\tilde{x} = (3/7, 4/7) ≈ (0.4286, 0.5714))
* 이 점은 **|0.4286| + |0.5714| ≈ 1**
  → 마름모 위로 내려옴

대충 그림:

```text
      y ↑
    1 |      * (0,1)
 0.8 |
 0.6 |        x̃ (≈0.43, 0.57)
 0.4 |
 0.2 |
    0 +--------------------→ x
       0   0.4   0.8   1
```

느낌:

* (3,4)를 **L1 길이가 1 되도록** 줄인 버전

> 👉 **L1 정규화 요약**
> “벡터를 자기 L1 길이(|x₁|+…+|xₙ|)로 나눠서,
> **절댓값 합이 1인 벡터**로 만드는 것”
> (그래서 종종 “비율/분포”처럼 해석하기 좋음)

---

## 4. L1 vs L2를 딱 ASCII로 비교

똑같이 (3,4)라는 점이 있을 때:

```text
      y ↑
    1 |       * (0,1)
      |    L2:   x̂ ≈ (0.6, 0.8)
      |   L1: x̃ ≈ (0.43,0.57)
      |
    0 +----------------------→ x
       0   0.4   0.6    1
```

* 둘 다 원래 (3,4)에서 **방향은 비슷하게** 줄어들었는데,
* L2는 “원 위로”,
* L1은 “마름모 위로” 올라감.

그래서:

* **L2 정규화**:

  * “길이 = 1”인 **원(원통형 구)** 위에 점들이 놓임
  * 코사인/유클리드와 궁합 좋음 → 임베딩에서 제일 자주 씀

* **L1 정규화**:

  * “좌표 절댓값 합 = 1”인 **마름모/단체(simplex)** 위에 점들이 놓임
  * “각 축의 비율” 같은 느낌을 줄 때 좋음 (확률분포, 카운트 비율 등)

---

## 한 줄 요약

* **L2 정규화**

  * `x / ||x||₂`
  * “벡터를 **길이 1짜리 화살표**로 만든다”
  * 원 / 구(surface of sphere) 위에 점들이 놓임

* **L1 정규화**

  * `x / ||x||₁`
  * “벡터를 **절댓값 합이 1인 벡터**로 만든다”
  * 마름모 / 다이아몬드 / 단체(simplex) 위에 점들이 놓임




## 벡터 유사도
2 차원 공간에 두 문장의 임베딩 벡터가 있다고 상상해보자.
- `벡터 A`: "강아지가 귀여워" → [3, 4]
- `벡터 B`: "고양이가 사랑스러워" → [4, 3]
```text
    ↑ (y축)
  5 |
  4 |    A(3,4)
  3 |       B(4,3)
  2 |
  1 |
  0 |________→ (x축)
    0 1 2 3 4 5
```
여기서 A와 B는 좌표가 약간 다르지만,
둘 다 “(대략) 오른쪽 위를 향하는 벡터”라는 의미에서
방향이 비슷한 벡터라고 볼 수 있다.

### 각도는 같고, 크기만 다른 경우(개념 그림)

아래는 “각도(방향)는 같고 크기만 다른” 상황을 개념적으로 표현한 그림이다.
```
각도는 같다.
        ↑
        |
        |  /  방향은 같은데
        | /   길이(크기)만 다름
        |/
        •────→
```
### 크기는 다를 수 있다.
```
        ↑
      8 |       • C(6,8) "매우 긍정적"
      6 |     /
      4 |    • B(3,4) "긍정적"  
      2 |  /
      0 •────────→
        0   ..  8
```
둘은 같은 방향(각도)이지만, C가 더 긴 벡터이다. 즉, 방향(의미 패턴)은 같은데 “강도/세기”만 두 배라고 볼 수 있다.


### Cosine Similarity (각도 기반)
**계산법**: 
- cos(θ) = (A·B) / (|A| × |B|)
```
A·B = 3×4 + 4×3 = 24
|A| = √(3²+4²) = 5
|B| = √(4²+3²) = 5
cosine = 24 / (5×5) = 0.96
```
**특징**:
- 벡터 간의 **`각도`** 만 본다. (방향성만 본다는 얘기)
- 벡터의 크기는 무시
- 결과가 -1 ~ 1 (1에 가까울 수록 유사)

**언제?**:
- 문서 길이가 달라도 의미가 비슷하면 유사하다고 판단하고 싶을 때
  - 짧은 트윗 vs 긴 블로그 글
    - 같은 주제면 유사하다고 봄

## Dot Product (각도 + 크기 기반)
**계산법**:
-  A·B = A₁×B₁ + A₂×B₂
```
3×4 + 4×3 = 24
```
**특징**:
- 각도 + 벡터의 크기(magnitude) 둘 다 고려
- 정규화 안 된 벡터에선 큰 벡터가 더 높은 점수를 받음
- 결과가 음수나 양수

**언제?**:
- 임베딩 모델이 이미 정규화(L2) 되어 있고, 약간의 성능 이득이 필요할 때
- 벡터 크기 자체가 중요한 의미를 가질 때
  - 매우 긍정적(큰 벡터) vs 조금 긍정적(작은 벡터) 를 구분하고 싶을 때
  - 추천 시스템에서 선호도 강도를 반영하고 싶을 때

**참고**:
- 모델이 어떻게 학습됐냐에 따라 길이가 “확신도”를 반영하기도 하고 그냥 아무 의미 없는 스케일일 수도 있어서,
- 그래서 실무에서는 아예 길이를 1로 맞춰버리고(정규화) 각도만 보기도 함.
## Euclidean Distance (거리 기반)
**계산법**:
- distance = √((A₁-B₁)² + (A₂-B₂)²)
```
# √((3-4)² + (4-3)²) = √(1 + 1) = 1.41
```
**특징**:
- 두 점 사이의 직선 거리
- 작을수록 유사함 (0에 가까울수록 가까움)
- 공간상의 **실제 거리**를 측정

**계산법**:
- 임베딩 공간에서 "얼마나 멀리 떨어져 있나"가 중요할 때
- 클러스터링에서 같은 그룹인지 판단할 때
  - 얼굴 인식에서 "이 사람이 맞나" 판단할 때
  - 이상치 탐지  

## 예시
### 다른 각도, 비슷한 크기
```
        ↑
      5 |  • D(0,5) "슬픔"
        |  |
      3 |  |
        |  |
      0 •──────→
        0  3  5
           |
           • E(5,0) "분노"

각도: 90도 차이 (완전히 다른 방향)
크기: 둘 다 5 정도로 비슷
```
- Cosine
  - 각도가 90도니까 0으로 전혀 안 비슷
- Dot Product
  - 0x5 + 5x0 = 0으로 전혀 안 비슷
- Euclidean
  - 거리 재니까 7.07로 꽤 멀리 떨어짐

### 비슷한 각도, 다른 크기
```
        ↑
      4 |     • "AI는 정말 대단해요!!!" (4,3)
      3 |    /•  "AI 괜찮네" (2,1.5)
      2 |   /
      1 |  /
      0 •────────→
        0 1 2 3 4

두 문장 모두 "AI 긍정" 방향
하지만 감정의 '강도'가 다름
```
- Cosine
  - 방향이 거의 같으니 의미는 같다고 생각
- Dot Product
  - 방향은 같지만, 크기를 반영해서 차이가 남
- Euclidean
  - 2.5만큼 떨어져 있으니 감정 강도가 차이가 난다고 판단

